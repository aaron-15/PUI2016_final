{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUI2016 Final \n",
    "\n",
    "## DATA:\n",
    "\n",
    "I prepared datasets that are partially processed in advance. You can work with those, or gather and process the data by yourself, or begin working with the preprocessed data and then go back to get and wrangle the original data to obtain the dataset I gave you (that is what I would do). Generally each step outlined in the instructions earns you a point, or a fraction of a point for being done partially. See [PUI2016_RULES](https://github.com/fedhere/PUI2016_final/blob/master/PUI2016_RULES.ipynb) for more details.\n",
    "     \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Geospatial files: \n",
    " you will need to join the census dataframes with GeoDataFrames which contain the shapes of the census tracts, for the second part, and zipcodes, for the first part.\n",
    " \n",
    " you are going to need: \n",
    " \n",
    "- a census tract shape file : you have used on in the [geospatial lab]( https://github.com/fedhere/PUI2016_fb55/tree/master/Lab9_SRK325) and homework, and I uploaded one on my CartoDB account (see below). Any reproducible way to upload one is ok.\n",
    "- a zipcode shapefile : you have used on in [HW11](https://github.com/fedhere/PUI2016_fb55/blob/master/HW11_fb55/HW11_Assignment2_solution.ipynb) \n",
    "- a smaller resloution contour file may also be useful, such as [this one](http://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/nybb_16d.zip), but it is not necessary \n",
    " \n",
    "I uploaded the census tract geojson on my cartoDB as **table_2010_census_tracts** and you can use the function defined below with the appropriate call for geojson and reading in the file appropriately\n",
    "\n",
    "\n",
    "    datastream = queryCartoDB(query, format='GeoJSON')\n",
    "    datageo  = json.loads(datastream.read())\n",
    "    data = gpd.GeoDataFrame.from_features(datageo['features'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busnisses Census Data\n",
    "In the first part you need the number of businesses per zipcode. \n",
    "You used this very dataset in a homework [HW11](https://github.com/fedhere/PUI2016_fb55/blob/master/HW11_fb55/HW11_Assignment2_solution.ipynb). If you need further help look [here](https://docs.google.com/document/d/1KtJapvlkU8l8-mjxOs8K8PNxmK5xxyNIUyvimFiRDjA/edit?usp=sharing)\n",
    "Use that homework to point you to the lines of code you need to download the files (you only need the 2000 and 2010 file) and how to read them. Merge them to the zipcode GeoDataFrame just like you did then!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  Census data for demographics: \n",
    " \n",
    "You have to extract the ***total population, median age, and percentage of white population*** from Census data for the 2000 and 2010 ***decennial census data***. You can find the relevant dataset on American Fact Finder using the advanced search https://factfinder.census.gov/faces/nav/jsf/pages/searchresults.xhtml?refresh=t. If you cannot download the data from within the notebook (its hard) you must clearly state all the teps you take to obtain the dataset and provide the relevant URLs when possible. \n",
    "The ***income data*** is stored in different tables also available on American Fact Finder.  You want the median imcome per census tract for 2000 and 2010. You can use the ***annual estimate*** (you have to for 2000 and for consistency you should for 2010 as well). Same rules apply here as they did in the search for population, age, and diversity. \n",
    " \n",
    "**Alternatively** (no points lost) you can download the data with an SQL query from public data in cartoDB: I provide a function for that purpose below. Run the SQL query with the databse name and retrieve the columns you want (as you did in HW12, and Lab10_hv). \n",
    " \n",
    " We define a helper function queryCartoDB wraps around the SQL API of CartoDB. We can pass it a public data source (in the form of 'https://{ACCOUNT}.cartodb.com/api/v2/sql', where ACCOUNT is the owner of the data) and an SQL statement to query the data in various formats including CSV, JSON, and GeoJSON. The result returned from this function is a file-like object, which you can pass to a file readers such as Pandas' read_csv() or the JSON parser. In this final exam, all SQL-based data sets have been setup to be publicly available from the account fb55, so, you don't have to use your accounts.  The SQL contains 4 sources - one for demographic info and one for income info for each year.\n",
    "\n",
    "- Census 2000: DEC_00_SF1_DP1\n",
    "- Census 2010: DEC_10_SF1_SF1DP1\n",
    "- Income Census 2000: DEC_00_SF3_DP3_with_ann.csv\n",
    "- Income Census 2010: ACS_10_5YR_S1901_with_ann.csv\n",
    "\n",
    "From the decennial census datasets you should end up with the columns corresponding to \n",
    "- The Geo identifiers \n",
    "- Total population (Number)\n",
    "- White population (Percentage)\n",
    "- Median age\n",
    "\n",
    "From the income census datasets you should end up with the columns corresponding to \n",
    "- The Geo identifiers \n",
    "- The median household income (Number)\n",
    "\n",
    "You can consult the metadata files to find out which columns give you the relevant data and include them in your SQL query . The files are uploaded uploaded in [PUI12016data](http://cosmo.nyu.edu/~fb55/PUI2016/data/) : they have the same name as the corresponding file in the SQL CartoDB database, but the extension is \\_metadata.csv, and the capitals will be lower case letters in the cartoDB names (cartoDB changes them upon upoading, but the SQL query is insensitive to that).\n",
    "\n",
    "In the next cell, I'm going to define the helper function. You can copy and paste this code in your notebook. This is the Python2 version, but in [Lab10_hv](https://github.com/fedhere/PUI2016_fb55/tree/master/Lab11_hv) you also had the Python3 verison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import ast\n",
    "import json\n",
    "import urllib\n",
    "import urllib2\n",
    "from cStringIO import StringIO\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "SQL_SOURCE = 'https://fb55.cartodb.com/api/v2/sql'\n",
    "\n",
    "def queryCartoDB(query, format='CSV', source=SQL_SOURCE):\n",
    "    \"\"\"queries data from CartoDB SQL database\n",
    "    Arguments:\n",
    "    query: a string like \n",
    "            SELECT colum_name_1, column_name_2 FROM database_name\n",
    "    format: the file format (e.g. CSV, GeoJson)\n",
    "    source: the sql database url link\n",
    "    Return:\n",
    "        database as a string to be read in with the appropriate function\n",
    "    \"\"\"\n",
    "    data = urllib.urlencode({'format': format, 'q': query})\n",
    "    try:\n",
    "        response = urllib2.urlopen(source, data)\n",
    "    except urllib2.HTTPError, e:\n",
    "        raise ValueError('\\n'.join(ast.literal_eval(e.readline())['error']))\n",
    "    except Exception:\n",
    "        raise\n",
    "    return StringIO(response.read())\n",
    "\n",
    "# call as:\n",
    "#datastream = queryCartoDB(query, format='CSV')\n",
    "#data       = pd.read_csv(database_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census data shortcut\n",
    "you can get the census data that I wrangled for you from these URLs\n",
    "\n",
    "[census2000](http://cosmo.nyu.edu/~fb55/PUI2016/data/census00_final.json) : http://cosmo.nyu.edu/~fb55/PUI2016/data/census00_final.json\n",
    "\n",
    "[census2010](http://cosmo.nyu.edu/~fb55/PUI2016/data/census10_final.json) : http://cosmo.nyu.edu/~fb55/PUI2016/data/census10_final.json            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**You will need to make spatial joints to merge files by ZIP code. Remember that the columns you merge on have to have the same values, and the same types! (both integers, or both strings) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
